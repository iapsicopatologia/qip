{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Caminho para o arquivo xlsx local\n",
    "file_path = './banco_dados.xlsx'\n",
    "# Leitura do arquivo xlsx usando pandas\n",
    "df = pd.read_excel(file_path, sheet_name='TDados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, f_oneway, kruskal\n",
    "\n",
    "def check_feature_representativeness(df, target_col):\n",
    "    \"\"\"\n",
    "    Verifica, de forma estatística básica, a representatividade de cada feature\n",
    "    em relação ao target (numérico).\n",
    "    \n",
    "    1. Identifica se a feature é numérica ou categórica.\n",
    "    2. Para features numéricas: faz correlação (Pearson) com target.\n",
    "    3. Para features categóricas: faz ANOVA ou Kruskal-Wallis (exemplo).\n",
    "    \"\"\"\n",
    "\n",
    "    # Separar X (features) e y (target)\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "\n",
    "    # Para armazenar resultados\n",
    "    resultados_num = []\n",
    "    resultados_cat = []\n",
    "\n",
    "    # Loop em cada coluna de X\n",
    "    for feature in X.columns:\n",
    "        serie = X[feature]\n",
    "\n",
    "        # Vamos arbitrar um critério simples: se número de valores únicos for\n",
    "        # maior que, digamos, 20% do df, consideramos \"numérica\"\n",
    "        # (Ajuste conforme a natureza dos seus dados)\n",
    "        limiar_categ = int(0.2 * len(df))\n",
    "\n",
    "        if serie.nunique() >= limiar_categ and pd.api.types.is_numeric_dtype(serie):\n",
    "            # Trata como numérica\n",
    "            # Calcula correlação de Pearson (r) e p-value\n",
    "            r, p_value = pearsonr(serie, y)\n",
    "            resultados_num.append((feature, r, p_value))\n",
    "\n",
    "        else:\n",
    "            # Trata como categórica\n",
    "            # Precisamos agrupar os valores de y por cada categoria\n",
    "            categorias = serie.unique()\n",
    "            grupos = []\n",
    "            for cat in categorias:\n",
    "                grupos.append(y[serie == cat])\n",
    "\n",
    "            # Exemplo: ANOVA (F-oneway) se assumirmos proximidade com normalidade\n",
    "            # ou Kruskal-Wallis se preferir não assumir.\n",
    "            # Aqui, vamos exemplificar com ANOVA:\n",
    "            if len(grupos) > 1:\n",
    "                f_stat, p_value = f_oneway(*grupos)\n",
    "                resultados_cat.append((feature, f_stat, p_value, categorias))\n",
    "            # Se len(grupos) == 1, é uma feature praticamente \"constante\"; pouco útil.\n",
    "\n",
    "    # Imprimindo resultados\n",
    "    print(\"=== Análise de Features Numéricas ===\")\n",
    "    print(\"Feature         | Pearson_r  | p-value\")\n",
    "    for (feat, r, p) in sorted(resultados_num, key=lambda x: abs(x[1]), reverse=True):\n",
    "        print(f\"{feat:<15} | {r:>9.4f} | {p:>9.4g}\")\n",
    "\n",
    "    print(\"\\n=== Análise de Features Categóricas ===\")\n",
    "    print(\"Feature         | Estatística (F) | p-value | Categorias\")\n",
    "    for (feat, f_stat, p, cats) in sorted(resultados_cat, key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{feat:<15} | {f_stat:>16.4f} | {p:>8.4g} | {len(cats)} cat(s)\")\n",
    "\n",
    "    # Chamar a função para checar representatividade\n",
    "    check_feature_representativeness(df, target_col='Resp_13')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do DF após filtrar y != 0 e outliers: 22\n",
      "Dimensão de X: (22, 310)\n",
      "Dimensão de y: (22,)\n",
      "\n",
      "[BASELINE]\n",
      "MSE = 3.5772\n",
      "MAE = 1.3444\n",
      "R²  = -0.2713\n",
      "\n",
      "[INÍCIO DA BUSCA DE HIPERPARÂMETROS COM K-FOLD (10 folds)]\n",
      "\n",
      "Testando hiperparâmetros: {'units1': 32, 'units2': 16, 'units3': 8, 'units4': 4, 'activation': 'relu', 'learning_rate': 0.001, 'dropout_rate': 0.0, 'l2_reg': 0.0, 'use_batchnorm': False}\n",
      "Média do val_loss (MSE) nos folds = 13.4486\n",
      " -> Novo melhor modelo! val_loss: 13.4486\n",
      "\n",
      "Testando hiperparâmetros: {'units1': 64, 'units2': 32, 'units3': 16, 'units4': 8, 'activation': 'leaky', 'learning_rate': 0.001, 'dropout_rate': 0.2, 'l2_reg': 0.0001, 'use_batchnorm': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josuemorais\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média do val_loss (MSE) nos folds = 18.2925\n",
      "\n",
      "Testando hiperparâmetros: {'units1': 128, 'units2': 64, 'units3': 32, 'units4': 16, 'activation': 'selu', 'learning_rate': 0.001, 'dropout_rate': 0.3, 'l2_reg': 1e-05, 'use_batchnorm': True}\n",
      "Média do val_loss (MSE) nos folds = 16.4376\n",
      "\n",
      "Testando hiperparâmetros: {'units1': 128, 'units2': 64, 'units3': 32, 'units4': 16, 'activation': 'relu', 'learning_rate': 0.0001, 'dropout_rate': 0.0, 'l2_reg': 0.0001, 'use_batchnorm': True}\n",
      "Média do val_loss (MSE) nos folds = 13.7436\n",
      "\n",
      "Testando hiperparâmetros: {'units1': 64, 'units2': 32, 'units3': 16, 'units4': 8, 'activation': 'relu', 'learning_rate': 0.001, 'dropout_rate': 0.2, 'l2_reg': 0.001, 'use_batchnorm': False}\n",
      "Média do val_loss (MSE) nos folds = 9.6484\n",
      " -> Novo melhor modelo! val_loss: 9.6484\n",
      "\n",
      "Testando hiperparâmetros: {'units1': 64, 'units2': 32, 'units3': 16, 'units4': 8, 'activation': 'selu', 'learning_rate': 0.0001, 'dropout_rate': 0.2, 'l2_reg': 0.001, 'use_batchnorm': True}\n",
      "Média do val_loss (MSE) nos folds = 19.3607\n",
      "\n",
      "Testando hiperparâmetros: {'units1': 64, 'units2': 32, 'units3': 16, 'units4': 8, 'activation': 'leaky', 'learning_rate': 0.0001, 'dropout_rate': 0.0, 'l2_reg': 0.0, 'use_batchnorm': True}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 289\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmodel_fn\u001b[39m():\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m build_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m--> 289\u001b[0m avg_val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model_kfold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_full\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train_full\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Aumentamos para 200 épocas\u001b[39;49;00m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Reduzindo batch_size (às vezes ajuda em dados pequenos)\u001b[39;49;00m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# 10 folds\u001b[39;49;00m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# maior paciência no early stopping\u001b[39;49;00m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMédia do val_loss (MSE) nos folds = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_val_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m avg_val_loss \u001b[38;5;241m<\u001b[39m best_val_loss:\n",
      "Cell \u001b[1;32mIn[47], line 181\u001b[0m, in \u001b[0;36mevaluate_model_kfold\u001b[1;34m(model_fn, X_data, y_data, epochs, batch_size, k, patience)\u001b[0m\n\u001b[0;32m    168\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[0;32m    169\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    170\u001b[0m     patience\u001b[38;5;241m=\u001b[39mpatience,\n\u001b[0;32m    171\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    172\u001b[0m )\n\u001b[0;32m    173\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(\n\u001b[0;32m    174\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    175\u001b[0m     factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    179\u001b[0m )\n\u001b[1;32m--> 181\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[0;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m min_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    191\u001b[0m val_losses\u001b[38;5;241m.\u001b[39mappend(min_val_loss)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[0;32m    914\u001b[0m   filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    915\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(\n\u001b[0;32m    916\u001b[0m           bound_args\n\u001b[0;32m    917\u001b[0m       )\n\u001b[0;32m    918\u001b[0m   )\n\u001b[1;32m--> 919\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    920\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_with_cond\u001b[39m(inner_args, inner_kwds):\n\u001b[0;32m    925\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "# 1. CARREGAMENTO, LIMPEZA (FILTRAGEM Y != 0) E POSSÍVEL TRATAMENTO DE OUTLIERS\n",
    "##############################################################################\n",
    "# 1.1. Filtrar linhas onde Resp_13 seja diferente de 0\n",
    "df = df[df['Resp_13'] != 0]\n",
    "# Exemplo: df = pd.read_csv(\"seu_arquivo.csv\")\n",
    "# Ajuste de acordo com seu caso real\n",
    "# ---------------------------------------------------------------\n",
    "# 1.2. Exemplo adicional: Remover outliers de y (Resp_13) acima de algum quantil, \n",
    "#     por exemplo, 99º percentil. Ajuste se fizer sentido para o seu caso.\n",
    "upper_quantile = df['Resp_13'].quantile(0.99)\n",
    "df = df[df['Resp_13'] < upper_quantile]\n",
    "\n",
    "print(f\"Tamanho do DF após filtrar y != 0 e outliers: {len(df)}\")\n",
    "\n",
    "# Separação em X e y\n",
    "X = df.drop(columns=['Resp_13'])\n",
    "y = df['Resp_13']\n",
    "\n",
    "print(\"Dimensão de X:\", X.shape)\n",
    "print(\"Dimensão de y:\", y.shape)\n",
    "\n",
    "##############################################################################\n",
    "# 2. TREINO/TESTE SPLIT E ESCALONAMENTO\n",
    "##############################################################################\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_full = scaler.fit_transform(X_train_full)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Baseline: prever média\n",
    "baseline_pred = np.full_like(y_test, fill_value=np.mean(y_train_full))\n",
    "baseline_mse = mean_squared_error(y_test, baseline_pred)\n",
    "baseline_mae = mean_absolute_error(y_test, baseline_pred)\n",
    "baseline_r2  = r2_score(y_test, baseline_pred)\n",
    "\n",
    "print(\"\\n[BASELINE]\")\n",
    "print(f\"MSE = {baseline_mse:.4f}\")\n",
    "print(f\"MAE = {baseline_mae:.4f}\")\n",
    "print(f\"R²  = {baseline_r2:.4f}\\n\")\n",
    "\n",
    "##############################################################################\n",
    "# 3. CONSTRUÇÃO DO MODELO (POSSÍVEIS 4 CAMADAS DENSAS) + ATIVAÇÕES\n",
    "##############################################################################\n",
    "def build_model(\n",
    "    # Camadas\n",
    "    units1=64, units2=32, units3=16, units4=8,\n",
    "    activation='relu',  # 'relu', 'leaky', 'selu'\n",
    "    # Hiperparâmetros de otimização\n",
    "    learning_rate=1e-3,\n",
    "    # Regularização\n",
    "    dropout_rate=0.0,\n",
    "    l2_reg=0.0,\n",
    "    use_batchnorm=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Rede neural com até 4 camadas densas (algumas podem ser pequenas).\n",
    "    Pode usar ReLU, LeakyReLU ou SELU. Inclui dropout, batchnorm, L2.\n",
    "    \"\"\"\n",
    "    regularizer = tf.keras.regularizers.l2(l2_reg) if l2_reg > 0 else None\n",
    "    \n",
    "    # Função auxiliar para ativação\n",
    "    def activation_layer(x, act):\n",
    "        if act == 'leaky':\n",
    "            return tf.keras.layers.LeakyReLU(alpha=0.01)(x)\n",
    "        elif act == 'selu':\n",
    "            return tf.keras.layers.Activation('selu')(x)\n",
    "        else:\n",
    "            return tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(X_train_full.shape[1],))\n",
    "\n",
    "    # 1ª camada densa\n",
    "    x = tf.keras.layers.Dense(\n",
    "        units1, \n",
    "        kernel_regularizer=regularizer,\n",
    "        kernel_initializer='he_normal'\n",
    "    )(inputs)\n",
    "    x = activation_layer(x, activation)\n",
    "    if use_batchnorm:\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "    if dropout_rate > 0:\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    # 2ª camada densa\n",
    "    x = tf.keras.layers.Dense(\n",
    "        units2,\n",
    "        kernel_regularizer=regularizer,\n",
    "        kernel_initializer='he_normal'\n",
    "    )(x)\n",
    "    x = activation_layer(x, activation)\n",
    "    if use_batchnorm:\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "    if dropout_rate > 0:\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # 3ª camada densa\n",
    "    x = tf.keras.layers.Dense(\n",
    "        units3,\n",
    "        kernel_regularizer=regularizer,\n",
    "        kernel_initializer='he_normal'\n",
    "    )(x)\n",
    "    x = activation_layer(x, activation)\n",
    "    if use_batchnorm:\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "    if dropout_rate > 0:\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    # 4ª camada densa\n",
    "    x = tf.keras.layers.Dense(\n",
    "        units4,\n",
    "        kernel_regularizer=regularizer,\n",
    "        kernel_initializer='he_normal'\n",
    "    )(x)\n",
    "    x = activation_layer(x, activation)\n",
    "    if use_batchnorm:\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "    if dropout_rate > 0:\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Saída\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "##############################################################################\n",
    "# 4. FUNÇÃO DE K-FOLD CROSS-VALIDATION (COM CALLBACKS)\n",
    "##############################################################################\n",
    "def evaluate_model_kfold(\n",
    "    model_fn,\n",
    "    X_data,\n",
    "    y_data,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    k=10,            \n",
    "    patience=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Executa K-fold cross-validation para o modelo definido por model_fn.\n",
    "    Retorna a média do menor val_loss (MSE) em cada fold.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    val_losses = []\n",
    "    y_data = np.array(y_data)\n",
    "\n",
    "    for train_index, val_index in kf.split(X_data):\n",
    "        X_tr, X_val = X_data[train_index], X_data[val_index]\n",
    "        y_tr, y_val = y_data[train_index], y_data[val_index]\n",
    "\n",
    "        model = model_fn()\n",
    "        \n",
    "        # Callbacks\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=patience,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-7,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            X_tr, y_tr,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[early_stop, reduce_lr],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        min_val_loss = min(history.history['val_loss'])\n",
    "        val_losses.append(min_val_loss)\n",
    "    \n",
    "    return np.mean(val_losses)\n",
    "\n",
    "##############################################################################\n",
    "# 5. GRID DE HIPERPARÂMETROS COMBINANDO VARIAÇÕES (maior)\n",
    "##############################################################################\n",
    "param_grid = [\n",
    "    # 1) Rede \"menor\"\n",
    "    {\n",
    "        'units1': 32, 'units2': 16, 'units3': 8, 'units4': 4,\n",
    "        'activation': 'relu',\n",
    "        'learning_rate': 1e-3,\n",
    "        'dropout_rate': 0.0,\n",
    "        'l2_reg': 0.0,\n",
    "        'use_batchnorm': False\n",
    "    },\n",
    "    # 2) Rede \"média\"\n",
    "    {\n",
    "        'units1': 64, 'units2': 32, 'units3': 16, 'units4': 8,\n",
    "        'activation': 'leaky',\n",
    "        'learning_rate': 1e-3,\n",
    "        'dropout_rate': 0.2,\n",
    "        'l2_reg': 1e-4,\n",
    "        'use_batchnorm': True\n",
    "    },\n",
    "    # 3) Rede \"grande\", SELU\n",
    "    {\n",
    "        'units1': 128,'units2': 64,'units3': 32, 'units4': 16,\n",
    "        'activation': 'selu',\n",
    "        'learning_rate': 1e-3,\n",
    "        'dropout_rate': 0.3,\n",
    "        'l2_reg': 1e-5,\n",
    "        'use_batchnorm': True\n",
    "    },\n",
    "    # 4) Rede \"grande\", ReLU, LR menor\n",
    "    {\n",
    "        'units1': 128,'units2': 64,'units3': 32, 'units4': 16,\n",
    "        'activation': 'relu',\n",
    "        'learning_rate': 1e-4,\n",
    "        'dropout_rate': 0.0,\n",
    "        'l2_reg': 1e-4,\n",
    "        'use_batchnorm': True\n",
    "    },\n",
    "    # 5) Rede média, variação de dropout e L2\n",
    "    {\n",
    "        'units1': 64,'units2': 32,'units3': 16, 'units4': 8,\n",
    "        'activation': 'relu',\n",
    "        'learning_rate': 1e-3,\n",
    "        'dropout_rate': 0.2,\n",
    "        'l2_reg': 1e-3,\n",
    "        'use_batchnorm': False\n",
    "    },\n",
    "    # 6) Rede média + SELU, LR=1e-4\n",
    "    {\n",
    "        'units1': 64, 'units2': 32, 'units3': 16, 'units4': 8,\n",
    "        'activation': 'selu',\n",
    "        'learning_rate': 1e-4,\n",
    "        'dropout_rate': 0.2,\n",
    "        'l2_reg': 1e-3,\n",
    "        'use_batchnorm': True\n",
    "    },\n",
    "    # 7) Rede média + Leaky, sem dropout, LR=1e-4\n",
    "    {\n",
    "        'units1': 64, 'units2': 32, 'units3': 16, 'units4': 8,\n",
    "        'activation': 'leaky',\n",
    "        'learning_rate': 1e-4,\n",
    "        'dropout_rate': 0.0,\n",
    "        'l2_reg': 0.0,\n",
    "        'use_batchnorm': True\n",
    "    },\n",
    "    # 8) Rede grande + batchnorm, dropout 0.1, LR=1e-3, L2=1e-4\n",
    "    {\n",
    "        'units1': 128, 'units2': 64, 'units3': 32, 'units4': 16,\n",
    "        'activation': 'relu',\n",
    "        'learning_rate': 1e-3,\n",
    "        'dropout_rate': 0.1,\n",
    "        'l2_reg': 1e-4,\n",
    "        'use_batchnorm': True\n",
    "    }\n",
    "    # Você pode adicionar mais combinações, inclusive variar batch_size\n",
    "    # e epochs no evaluate_model_kfold, mas isso pode aumentar muito o tempo.\n",
    "]\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_params = None\n",
    "\n",
    "print(\"[INÍCIO DA BUSCA DE HIPERPARÂMETROS COM K-FOLD (10 folds)]\")\n",
    "\n",
    "##############################################################################\n",
    "# 6. RODAR A VALIDAÇÃO CRUZADA PARA CADA COMBINAÇÃO\n",
    "##############################################################################\n",
    "for params in param_grid:\n",
    "    print(f\"\\nTestando hiperparâmetros: {params}\")\n",
    "    \n",
    "    def model_fn():\n",
    "        return build_model(**params)\n",
    "    \n",
    "    avg_val_loss = evaluate_model_kfold(\n",
    "        model_fn=model_fn,\n",
    "        X_data=X_train_full,\n",
    "        y_data=y_train_full,\n",
    "        epochs=200,        # Aumentamos para 200 épocas\n",
    "        batch_size=16,     # Reduzindo batch_size (às vezes ajuda em dados pequenos)\n",
    "        k=10,              # 10 folds\n",
    "        patience=10        # maior paciência no early stopping\n",
    "    )\n",
    "    \n",
    "    print(f\"Média do val_loss (MSE) nos folds = {avg_val_loss:.4f}\")\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_params = params\n",
    "        print(f\" -> Novo melhor modelo! val_loss: {best_val_loss:.4f}\")\n",
    "\n",
    "print(f\"\\nMelhor configuração encontrada: {best_params}\")\n",
    "print(f\"Melhor val_loss médio (MSE): {best_val_loss:.4f}\")\n",
    "\n",
    "##############################################################################\n",
    "# 7. TREINO FINAL COM OS MELHORES PARÂMETROS ENCONTRADOS\n",
    "##############################################################################\n",
    "final_model = build_model(**best_params)\n",
    "\n",
    "# Callbacks para o treino final\n",
    "early_stop_final = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "reduce_lr_final = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = final_model.fit(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    epochs=300,           # mais épocas\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stop_final, reduce_lr_final],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "##############################################################################\n",
    "# 8. AVALIAÇÃO NO TESTE\n",
    "##############################################################################\n",
    "y_pred_test = final_model.predict(X_test)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "r2_test  = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"\\n[RESULTADOS NO CONJUNTO DE TESTE]\")\n",
    "print(f\"MSE  = {mse_test:.4f}\")\n",
    "print(f\"MAE  = {mae_test:.4f}\")\n",
    "print(f\"R²   = {r2_test:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
