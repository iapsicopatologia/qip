{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import base64\n",
    "import hashlib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import List, Dict\n",
    "from typing import Callable\n",
    "\n",
    "# Caminho para o arquivo xlsx local\n",
    "file_path = './banco_dados.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções de conversão\n",
    "def substituir_string(texto, lista_substituicoes):\n",
    "    for antigo, novo in lista_substituicoes:\n",
    "        texto = texto.replace(antigo, novo)\n",
    "    return texto\n",
    "\n",
    "def string_to_unique_float(s: str) -> float:\n",
    "    # Gera um hash MD5 da string\n",
    "    md5_hash = hashlib.md5(s.encode()).hexdigest()\n",
    "    # Converte o hash em um número inteiro\n",
    "    int_value = int(md5_hash, 16)\n",
    "    # Normaliza o valor para o intervalo entre [0,1] e retorna\n",
    "    return int_value % (10**8) / (10**8)\n",
    "\n",
    "def replace_with_other(dataResp: Dict[str, list[str]],colNum: int, text: str,list: List,func: Callable[[str], str] = string_to_unique_float):\n",
    "    text = substituir_string(text,list)\n",
    "    if text.startswith(\"other:\") :\n",
    "        appendData(dataResp, f'Resp_{colNum}', func(text.replace(\"other:\",\"\")))\n",
    "    else:\n",
    "        appendData(dataResp, f'Resp_{colNum}', text)  \n",
    "\n",
    "def appendData(dataResp: Dict[str, list[str]], key: str, colData: str):\n",
    "    try:\n",
    "        dataResp[key].append(colData)\n",
    "    except KeyError:\n",
    "        dataResp[key] = [colData]\n",
    "\n",
    "\n",
    "def trataCol(dataResp: Dict[str, list[str]], colNum: int, colData: str, timeAtual: pd.Timestamp, timeAnterior: pd.Timestamp):\n",
    "    timeElipsed = (timeAtual - timeAnterior).total_seconds()    \n",
    "    colData = colData.replace(\"other;\", \"other:\").replace(\"Sucess;\", \"\").replace(\"Sucess\", \"\")    \n",
    "    match colNum:\n",
    "        case 2:\n",
    "            resp = []\n",
    "            for index,item in enumerate(colData.split(\";\")):\n",
    "                match index:\n",
    "                    case 0: # Que horas são neste instante?\n",
    "                        hora = item\n",
    "                    case 1: # Data de hoje?\n",
    "                        # Calcula o quanto o entrevistado estava errado em noção do tempo\n",
    "                        appendData(dataResp, 'Resp_1', (timeAtual - pd.to_datetime(f\"{item} {hora}\", dayfirst=True)).total_seconds())\n",
    "                    case 2: # Qual a sua Idade?\n",
    "                        appendData(dataResp, 'Resp_2', item)                       \n",
    "                    case 3: # Gênero *\n",
    "                        replace_with_other(dataResp,index,item,[(\"Feminino\", \"0\"), (\"Masculino\", \"1\")])                         \n",
    "                    case 4: # Qual foi o sexo atribuído no seu nascimento?\n",
    "                        replace_with_other(dataResp,index,item,[(\"Feminino\", \"0\"), (\"Masculino\", \"1\")])\n",
    "                    case 5: # Assinale a alternativa que identifica a sua Cor ou Raça:\n",
    "                        appendData(dataResp, f'Resp_{index}', string_to_unique_float(item.replace(\"other:\",\"\")))                        \n",
    "                        # replace_with_other(dataResp,index,item,[(\"Preta\", \"0\"), (\"Branca\", \"1\"), (\"Parda\", \"2\"), (\"Amarela\", \"3\"), (\"IndÍgena\", \"4\")])\n",
    "                    case 6: # Dentro de sua família, você é o(a) único(a) filho(a)?\n",
    "                        replace_with_other(dataResp,index,item,[(\"Sim\", \"0\")],lambda x: x)\n",
    "                    case 7: # Qual o seu estado civil?\n",
    "                        appendData(dataResp, f'Resp_{index}', string_to_unique_float(item.replace(\"other:\",\"\")))   \n",
    "                    case 8: # Possui filhos(as)?\n",
    "                        replace_with_other(dataResp,index,item,[(\"Sim\", \"0\")],lambda x: x) \n",
    "                    case 9: # Possui filhos(as) menores de 6 anos?\n",
    "                        replace_with_other(dataResp,index,item,[(\"Não\", \"0\"), (\"Sim\", \"1\")])    \n",
    "                    case 10: # Religião *\n",
    "                        replace_with_other(dataResp,index,item,[(\"Sem religião\", \"0\")])\n",
    "                    case 11: # Escolaridade *\n",
    "                        replace_with_other(dataResp,index,item,[(\"Sem Escolaridade\", \"0.0\"),(\"Ensino Fundamental (1º grau) incompleto\", \"0.1\"),(\"Ensino Fundamental (1º grau) completo\", \"0.2\"),(\"Ensino Médio (2º grau) incompleto\", \"0.3\"),(\"Ensino Médio (2º grau) completo\", \"0.4\"),(\"Superior Incompleto\", \"0.55\"),(\"Superior Completo\", \"0.7\"),(\"Mestrado\", \"0.85\"),(\"Doutorado\", \"1\")])\n",
    "                    case 12: # Renda familiar mensal de sua casa (somatória)\n",
    "                        replace_with_other(dataResp,index,item,[(\"Até 1 salário mínimo\", \"0.0\"),(\"Mais de 1 a 2 salários mínimos\", \"0.15\"),(\"Mais de 2 a 3 salários mínimos\", \"0.3\"),(\"Mais de 3 a 5 salários mínimos\", \"0.45\"),(\"Mais de 5 a 8 salários mínimos\", \"0.6\"),(\"Mais de 8 a 12 salários mínimos\", \"0.75\"),(\"Mais de 12 a 20 salários mínimos\", \"9.0\"),(\"Mais de 20 salários mínimos\", \"1.0\")])                     \n",
    "                appendData(dataResp, f'Elipsed_{index}', timeElipsed)                            \n",
    "            return resp\n",
    "        case 3:  \n",
    "            replace_with_other(dataResp,colNum,colData,[(\";\", \"\"),(\"Não\", \"0\")])\n",
    "            appendData(dataResp, f'Elipsed_{colNum}', timeElipsed)                               \n",
    "        case _:\n",
    "            appendData(dataResp, f'Resp_N{colNum}', re.sub(r'<optimized out>#\\w+\\((Sim|Não)\\)', r'\\1', colData))\n",
    "            appendData(dataResp, f'Elipsed_N{colNum}', timeElipsed)                \n",
    "            return [colData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m         timeAnterior \u001b[38;5;241m=\u001b[39m timeAtual \n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Cria o novo DataFrame com os dados processados\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m df_novo \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataResp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Usando ExcelWriter para adicionar a nova aba ao arquivo Excel existente com if_sheet_exists='replace'\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mExcelWriter(file_path, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenpyxl\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, if_sheet_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m writer:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# Leitura do arquivo xlsx usando pandas\n",
    "df = pd.read_excel(file_path, sheet_name='BDados')\n",
    "\n",
    "# Inicializa variáveis necessárias\n",
    "dataResp = {}\n",
    "count = 0\n",
    "timeAnterior = []  # Inicializa timeAnterior como uma lista vazia\n",
    "\n",
    "# Loop para processar colunas que começam com \"Tela\"\n",
    "for indexCol, colStr in enumerate(df.columns):\n",
    "\n",
    "    if colStr.startswith(\"Tela\") and df.iloc[0, indexCol] != \"\" and pd.notna(df.iloc[0, indexCol]):\n",
    "        timeAtual = []\n",
    "        timeElipsed = []\n",
    "        value = []\n",
    "        \n",
    "        colNum = int(re.search(r\"Tela (\\d+)\", colStr).group(1))\n",
    "        \n",
    "        for indexRow in range(df.shape[0]):\n",
    "            cell_value = str(df.iloc[indexRow, indexCol])\n",
    "            match = re.match(r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}) - (.+)\", cell_value)\n",
    "            \n",
    "            if match:\n",
    "                timeAtual.append(pd.to_datetime(match.group(1)))\n",
    "                if colNum != 1:                                    \n",
    "                    trataCol(dataResp, colNum, match.group(2), timeAtual[-1], timeAnterior[indexRow]) # globals()[f\"func_tela_colNum\"](match.group(2))\n",
    "            else:\n",
    "                print(\"Ocorreu um erro ao processar a célula:\", cell_value)\n",
    "        \n",
    "        timeAnterior = timeAtual \n",
    "        \n",
    "# Cria o novo DataFrame com os dados processados\n",
    "df_novo = pd.DataFrame(dataResp)\n",
    "\n",
    "# Usando ExcelWriter para adicionar a nova aba ao arquivo Excel existente com if_sheet_exists='replace'\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    df_novo.to_excel(writer, sheet_name='TDados', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
