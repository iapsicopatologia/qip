{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import base64\n",
    "import hashlib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Caminho para o arquivo xlsx local\n",
    "file_path = './banco_dados.xlsx'\n",
    "\n",
    "# Leitura do arquivo xlsx usando pandas\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções de conversão\n",
    "def string_to_unique_float2(s: str) -> float:\n",
    "    # Gera um hash MD5 da string\n",
    "    md5_hash = hashlib.md5(s.encode()).hexdigest()\n",
    "    # Converte o hash em um número inteiro\n",
    "    int_value = int(md5_hash, 16)\n",
    "    # Normaliza o valor para o intervalo entre 0 e 1\n",
    "    normalized_value = int_value % (10**8) / (10**8)\n",
    "    return normalized_value\n",
    "\n",
    "def string_to_unique_float(texto: str) -> float:\n",
    "    texto_bytes = texto.encode('utf-8')\n",
    "    numero_base64 = base64.b64encode(texto_bytes)\n",
    "    numero_unico = int.from_bytes(numero_base64, byteorder='big')\n",
    "    max_valor = 2 ** (len(numero_base64) * 8) - 1  # Maior valor possível para o número\n",
    "    return numero_unico / max_valor\n",
    "\n",
    "def string_para_numero_unico(texto):\n",
    "    hash_md5 = hashlib.md5(texto.encode())\n",
    "    numero_unico = int(hash_md5.hexdigest(), 16)\n",
    "    return numero_unico\n",
    "\n",
    "def string_para_numero(texto):\n",
    "    texto_bytes = texto.encode('utf-8')\n",
    "    numero_base64 = base64.b64encode(texto_bytes)\n",
    "    numero_unico = int.from_bytes(numero_base64, byteorder='big')\n",
    "    return numero_unico\n",
    "\n",
    "def numero_para_string(numero):\n",
    "    numero_bytes = numero.to_bytes((numero.bit_length() + 7) // 8, byteorder='big')\n",
    "    texto_original = base64.b64decode(numero_bytes).decode('utf-8')\n",
    "    return texto_original\n",
    "\n",
    "# Função para extrair data e valores, substituindo valores por números\n",
    "def extrair_data_valores(data, linha):\n",
    "    value = []\n",
    "    timeElipsed = []\n",
    "    time_point_anterior = 0\n",
    "    for j, colStr in enumerate(data.columns):\n",
    "        if colStr.startswith(\"Tela\") and data[colStr].iloc[0] != \"\":\n",
    "            colNum = int(re.search(r\"Tela (\\d+)\", colStr).group(1))\n",
    "            \n",
    "            # Converte `data.iloc[linha, j]` para string\n",
    "            cell_value = str(data.iloc[linha, j])\n",
    "            \n",
    "            match = re.match(r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}) - (.+)\", cell_value)\n",
    "            if match:\n",
    "                time_point_atual = pd.to_datetime(match.group(1))\n",
    "                if colNum == 1:\n",
    "                    time_point_anterior = time_point_atual\n",
    "                else:\n",
    "                    if colNum != 42 and colNum != 74 and colNum != 75:\n",
    "                        valores = match.group(2)\n",
    "                        valores = re.sub(r'<optimized out>#\\w+\\((Sim|Não)\\)', r'\\1', valores)\n",
    "                        valores = valores.replace(\"other;\", \"\").replace(\"Sucess;\", \"\").replace(\"Sucess\", \"\")\n",
    "                        valueAux = list(map(string_para_numero_unico, valores.split(\";\")))\n",
    "                        timeElipsed += [(time_point_atual - time_point_anterior).total_seconds() for _ in range(len(valueAux))]\n",
    "                        time_point_anterior = time_point_atual\n",
    "                        value += valueAux\n",
    "    return value, timeElipsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop para processar colunas que começam com \"Tela\"\n",
    "valueAux, timeElipsedAux = extrair_data_valores(df, 0)\n",
    "value = np.matrix(valueAux)\n",
    "timeElipsed =np.matrix(timeElipsedAux)\n",
    "for linha in range(df.shape[0]-1):\n",
    "    valueAux, timeElipsedAux = extrair_data_valores(df, linha+1)\n",
    "    value = np.vstack(value, np.array(valueAux))\n",
    "    timeElipsed =np.vstack(timeElipsed, np.array(timeElipsedAux))\n",
    "\n",
    "# Exibir os resultados para conferência\n",
    "# print(numero_para_string(value[15][13]))\n",
    "\n",
    "# Conversão das listas para matrizes numpy\n",
    "value = np.array(value, dtype=object)\n",
    "timeElipsed = np.array(timeElipsed, dtype=object)\n",
    "\n",
    "# Certifique-se de que todos os arrays em `value` e `timeElipsed` tenham o mesmo comprimento\n",
    "# max_len = max(len(row) for row in value)\n",
    "# value = np.array([np.pad(row, (0, max_len - len(row)), constant_values=np.nan) for row in value], dtype=float)\n",
    "# timeElipsed = np.array([np.pad(row, (0, max_len - len(row)), constant_values=np.nan) for row in timeElipsed], dtype=float)\n",
    "\n",
    "# Remove linhas com NaN no target (coluna 13)\n",
    "# mask = ~np.isnan(value[:, 13])\n",
    "# value = value[mask]\n",
    "# timeElipsed = timeElipsed[mask]\n",
    "\n",
    "# Separando a coluna 13 como target e criando a matriz de features\n",
    "X = np.hstack([value, timeElipsed])  # Adiciona `timeElipsed` como uma feature extra\n",
    "y = value[:, 13]  # Coluna 13 é o target\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalonamento dos dados\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Definir a estrutura da rede neural com TensorFlow\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Saída com um único valor para regressão\n",
    "])\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Treinar o modelo\n",
    "history = model.fit(X_train, y_train, epochs=5000, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Avaliar o modelo no conjunto de teste\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'MAE no conjunto de teste: {test_mae}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
